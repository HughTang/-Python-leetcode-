## 一、概述

Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。

键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。

Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用**复制**来扩展读性能，使用**分片**来扩展写性能。



## 二、数据类型

| 数据类型 |      可以存储的值      |                             操作                             |
| :------: | :--------------------: | :----------------------------------------------------------: |
|  STRING  | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作</br> 对整数和浮点数执行自增或者自减操作 |
|   LIST   |          列表          | 从两端压入或者弹出元素 </br> 对单个或者多个元素进行修剪，</br> 只保留一个范围内的元素 |
|   SET    |        无序集合        | 添加、获取、移除单个元素</br> 检查一个元素是否存在于集合中</br> 计算交集、并集、差集</br> 从集合里面随机获取元素 |
|   HASH   | 包含键值对的无序散列表 | 添加、获取、移除单个键值对</br> 获取所有键值对</br> 检查某个键是否存在 |
|   ZSET   |        有序集合        | 添加、获取、删除元素</br> 根据分值范围或者成员来获取元素</br> 计算一个键的排名 |



## 三、数据结构

### 字典

dictht 是一个散列表结构，使用拉链法解决哈希冲突。



### 跳跃表

是有序集合的底层实现之一。

跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。

在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。

![](https://i.loli.net/2021/04/10/mise6J3wjqod4Vn.png)

查找的层数使用随机数与加权的方式进行随机读取，权重按照越大的数可能查找到的概率越小，越大的数权重越小。

与红黑树等平衡树相比，跳跃表具有以下优点：

- 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
- 更容易实现；
- 支持无锁操作。



## 四、使用场景

### 计数器

可以对 String 进行自增自减运算，从而实现计数器功能。

Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。

### 缓存

将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。

### 查找表

例如 DNS 记录就很适合使用 Redis 进行存储。

查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。

### 消息队列

List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息

不过最好使用 Kafka、RabbitMQ 等消息中间件。

### 会话缓存

可以使用 Redis 来统一存储多台应用服务器的会话信息。

当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。

### 分布式锁实现

在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。

可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。

### 其它

Set 可以实现交集、并集等操作，从而实现共同好友等功能。

ZSet 可以实现有序性操作，从而实现排行榜等功能。

## 五、Redis 与 Memcached

两者都是非关系型内存键值数据库，主要有以下不同：

### 数据类型

Memcached 仅支持字符串类型，而 Redis 支持五种不同的数据类型，可以更灵活地解决问题。

### 数据持久化

Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。

### 分布式

Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。

Redis Cluster 实现了分布式的支持。

### 内存管理机制

- 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。
- Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。



## 六、键的过期时间

Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。

对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。



## 七、数据淘汰策略

可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。

Redis 具体有 6 种淘汰策略：

|      策略       |                         描述                         |
| :-------------: | :--------------------------------------------------: |
|  volatile-lru   | 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 |
|  volatile-ttl   |   从已设置过期时间的数据集中挑选将要过期的数据淘汰   |
| volatile-random |      从已设置过期时间的数据集中任意选择数据淘汰      |
|   allkeys-lru   |       从所有数据集中挑选最近最少使用的数据淘汰       |
| allkeys-random  |          从所有数据集中任意选择数据进行淘汰          |
|   noeviction    |                     禁止驱逐数据                     |

作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。

使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。

Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。



## 八、持久化

Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。

### RDB定时快照方式(snapshot)

将某个时间点的所有数据都存放到硬盘上。

可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。

如果系统发生故障，将会丢失最后一次创建快照之后的数据。

如果数据量很大，保存快照的时间会很长。



RDB持久化的触发分为手动触发和自动触发两种。

#### 1、手动触发

通过redis的**save**命令和**bgsave**命令，都可以生成RDB文件。 

一，save保存数据到磁盘的方式：

Redis Save 命令执行一个同步保存操作，将当前 Redis 实例的所有数据快照(snapshot)以 RDB 文件的形式保存到硬盘。

语法：redis 127.0.0.1:6379> SAVE
返回值：保存成功时返回 OK 。

 

二，BGSAVE保存数据到磁盘的方式：

BGSAVE 命令执行之后立即返回 OK ，然后 Redis **fork 出一个新子进程**，原来的 Redis 进程(父进程)继续处理客户端请求，而子进程则负责将数据保存到磁盘，然后退出。

客户端可以通过 LASTSAVE 命令查看相关信息，判断 BGSAVE 命令是否执行成功。

**bgsave命令执行过程中，只有fork子进程时会阻塞服务器**，而对于save命令，整个过程都会阻塞服务器，因此save已基本被废弃，**线上环境要杜绝save的使用**；后文中也将只介绍bgsave命令。此外，在自动触发RDB持久化时，Redis也会选择bgsave而不是save来进行持久化；下面介绍自动触发RDB持久化的条件。

#### 2、自动触发

自动触发最常见的情况是在配置文件中通过**save m n**，指定当m秒内发生n次变化时，会触发bgsave。 

save 900 1的含义是：当时间到900秒时，如果redis数据发生了至少1次变化，则执行bgsave

#### 3、save m n的原理如下：
1）按定时执行：每隔100ms，执行serverCron函数；
2）遍历所有save m n配置：在serverCron函数中，遍历save m n配置的保存条件，只要有一个条件满足，就进行bgsave。
     例如：

```shell
#  save
save 900 1
save 300 10
save 60 10000
```

   当三个save条件满足任意一个时，都会引起bgsave的调用。
3）对于每一个save m n条件，只有下面两条同时满足时才算满足：
   （1）当前时间 - lastsave > m
    （2）dirty >= n
4）save m n 执行日志

#### 4、bgsave实现流程：
1）Redis父进程首先判断：当前是否在执行save，或bgsave/bgrewriteaof（后面会详细介绍该命令）的子进程，如果在执行则bgsave命令直接返回。bgsave/bgrewriteaof 的子进程不能同时执行，主要是基于性能方面的考虑：两个并发的子进程同时执行大量的磁盘写操作，可能引起严重的性能问题。

2）FORK子进程：RDB写入时，会连内存一起Fork出一个新进程（子进程默认会与父进程共享相同的地址空间），遍历新进程内存中的数据写文件，这样就解决了些Snapshot过程中又有新的写入请求进来的问题。这个过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令 。父进程fork后，bgsave命令返回”Background saving started”信息并不再阻塞父进程，并可以响应其他命令

3）子进程创建RDB文件：RDB会先写到临时文件，完了再Rename成，这样外部程序对RDB文件的备份和传输过程是安全的。而且即使写新快照的过程中Server被强制关掉了，旧的RDB文件还在。

3）可配置是否进行压缩，压缩方法是字符串的LZF算法，以及将string形式的数字变回int形式存储。
4）动态所有停止RDB保存规则的方法：redis-cli config set save  ""

**该持久化的主要缺点是定时快照只是代表一段时间内的内存映像，所以系统重启会丢失上次快照与重启之间所有的数据。**

#### 5. RDB文件

RDB文件是经过压缩的二进制文件，下面介绍关于RDB文件的一些细节。 

- 存储路径 :RDB文件的存储路径既可以在启动前配置，也可以通过命令动态设定。 
- 配置：dir配置指定目录，dbfilename指定文件名。默认是Redis根目录下的dump.rdb文件。 
- 动态设定：Redis启动后也可以动态修改RDB存储路径，在**磁盘损害或空间不足时非常有用**；执行命令为config set dir {newdir}和config set dbfilename {newFileName} 

![这里写图片描述](https://img-blog.csdn.net/2018082919384321?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NDMzNzE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

1) REDIS：常量，保存着”REDIS”5个字符。 
2) db_version： **RDB文件的版本号**，注意不是Redis的版本号。 
3) SELECTDB 0 pairs：**表示一个完整的数据库**(0号数据库)，同理SELECTDB 3 pairs表示完整的3号数据库；只有当数据库中有键值对时，RDB文件中才会有该数据库的信息(上图所示的Redis中只有0号和3号数据库有键值对)；如果Redis中所有的数据库都没有键值对，则这一部分直接省略。其中：SELECTDB是一个常量，代表后面跟着的是数据库号码；0和3是数据库号码；pairs则存储了具体的键值对信息，包括key、value值，及其数据类型、内部编码、过期时间、压缩信息等等。 
4) EOF：常量，标志RDB文件正文内容结束。 
5) check_sum：前面所有内容的校验和；Redis在载入RBD文件时，会计算前面的校验和并与check_sum值比较，判断文件是否损坏。 
Redis默认采用LZF算法对RDB文件进行压缩。虽然压缩耗时，但是可以大大减小RDB文件的体积，因此压缩默认开启；可以通过命令关闭：



### **AOF基于语句追加方式**

AOF方式实际类似mysql的基于语句的binlog方式，即每条会使Redis内存数据发生改变的命令都会**追加到一个log文件**中，也就是说这个log文件就是Redis的持久化数据。

AOF持久化的触发分为手动触发和自动触发两种。

#### 1、手动触发

使用bgrewriteaof命令：Redis主进程fork子进程来执行AOF重写，这个子进程创建新的AOF文件来存储重写结果，防止影响旧文件。因为fork采用了写时复制机制，子进程不能访问在其被创建出来之后产生的新数据。Redis使用“AOF重写缓冲区”保存这部分新数据，最后父进程将AOF重写缓冲区的数据写入新的AOF文件中然后使用新AOF文件替换老文件。

``` shell
127.0.0.1:6379> bgrewriteoaf
OK
```

#### 2、自动触发

和RDB一样，配置在redis.conf文件里：

appendonly：是否打开AOF持久化功能，appendonly默认是 no, 改成appendonly yes。
appendfilename：AOF文件名称
appendfsync：同步频率
auto-aof-rewrite-min-size：如果文件大小小于此值不会触发AOF，默认64MB
auto-aof-rewrite-percentage：Redis记录最近的一次AOF操作的文件大小，如果当前AOF文件大小增长超过这个百分比则触发一次重写，默认100
启用AOF:appendonly yes  

关闭aof：

命令行关闭：关闭aof的命令：config set appendfsync no

配置文件：将appendonly设置为no，默认是 appendonly no ）

#### **3、AOF 工作原理**

将数据也是先存在内存，但是在存储的时候会使用调用**fsync**来完成对本次写操作的日志记录，这个日志文件其实是一个基于Redis网络交互协议的文本文件。AOF调用fsync也不是说全部都是无阻塞的，在某些系统上可能出现fsync阻塞进程的情况，对于这种情况可以通过配置修改，但默认情况不要修改。AOF最关键的配置就是关于调用fsync追加日志文件的平率，有两种预设频率，**always每次记录进来都添加**，**everysecond 每秒添加一次**。

同步命令到 AOF 文件的整个过程可以分为三个阶段：
1、**命令写入**：Redis 将执行完的命令、命令的参数、命令的参数个数等信息发送到 AOF 程序中。
2、**追加AOF缓存**：AOF 程序根据接收到的命令数据, 然后每隔一定的时间(比如每隔一秒）将协议内容写入AOF 缓冲区中.
3、**文件写入保存**：当达到 AOF同步条件，fsync 函数或者 fdatasync 函数会被调用，将 OS Cache 中的数据写入磁盘文件。
   随着AOF文件越来越大，需要定期对AOF文件进行**重写**，达到压缩的目的。

![img](https://img-blog.csdnimg.cn/20191217153230156.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ndWlzdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)

##### 第一阶段：命令写入
当一个 Redis 客户端需要执行命令时， 它通过网络连接， 将协议文本发送给 Redis 服务器。
比如说， 要执行命令 SET KEY VALUE ， 客户端将向服务器发送文本 "*3\r\n$3\r\nSET\r\n$3\r\nKEY\r\n$5\r\nVALUE\r\n" 。
服务器在接到客户端的请求之后， 它会根据协议文本的内容， 选择适当的命令函数， 并将各个参数从字符串文本转换为 Redis 字符串对象（StringObject）。

比如说， 针对上面的 SET 命令例子， Redis 将客户端的命令指针指向实现 SET 命令的 setCommand 函数， 并创建三个 Redis 字符串对象， 分别保存 SET 、 KEY 和 VALUE 三个参数（命令也算作参数）。

每当命令函数成功执行之后， 命令参数都会被传播到 AOF 程序， 以及 REPLICATION 程序（本节不讨论这个，列在这里只是为了完整性的考虑）。

这个执行并传播命令的过程可以用以下伪代码表示：

    if (execRedisCommand(cmd, argv, argc) == EXEC_SUCCESS):
    	if aof_is_turn_on():
            # 传播命令到 AOF 程序
            propagate_aof(cmd, argv, argc)
    
        if replication_is_turn_on():
            # 传播命令到 REPLICATION 程序
            propagate_replication(cmd, argv, argc)

##### 第二阶段：追加到AOF缓存
所有的写入命令会追加到aof_buf中
当命令被传播到 AOF 程序之后， 程序会根据命令以及命令的参数， 将命令从字符串对象转换回原来的协议文本。
比如说， 如果 AOF 程序接受到的三个参数分别保存着 SET 、 KEY 和 VALUE 三个字符串， 那么它将生成协议文本 "*3\r\n$3\r\nSET\r\n$3\r\nKEY\r\n$5\r\nVALUE\r\n" 。
协议文本生成之后， 它会被追加到 redis.h/redisServer 结构的 aof_buf 末尾。
redisServer 结构维持着 Redis 服务器的状态， aof_buf 域则保存着所有等待写入到 AOF 文件的协议文本：

```go
struct redisServer {
    // 其他域...
    sds aof_buf;
    // 其他域...
};
```

至此， 追加命令到缓存的步骤执行完毕。综合起来，整个缓存追加过程可以分为以下三步：

接受命令、命令的参数、以及参数的个数、所使用的数据库等信息。
将命令还原成 Redis 网络通讯协议。
将协议文本追加到 aof_buf 末尾。
##### 第三阶段：文件写入和保存
AOF缓冲区根据对应的策略向硬盘做同步操作。每当服务器常规任务函数被执行、 或者事件处理器被执行时， aof.c/flushAppendOnlyFile 函数都会被调用， 这个函数执行以下两个工作：系统调用write和fsync说明
WRITE：根据条件，将aof_buf中的缓存写入到 AOF 文件，即系统调用write写入os cache。
SAVE：根据条件，调用fsync或 fdatasync 函数，将AOF文件保存到磁盘中。

两个步骤都需要根据一定的条件来执行， 而这些条件由 AOF 所使用的保存模式来决定， 以下小节就来介绍 AOF 所使用的三种保存模式， 以及在这些模式下， 步骤 WRITE 和 SAVE 的调用条件。
##### AOF文件重写（Rewrite）
AOF是redis的一种持久化方式，用来记录所有的写操作，但是随着时间增加，aof文件会越来越大，所以需要进行重写，将内存中的数据重新以命令的方式写入aof文件。在重写的过程中，由于redis还会有新的写入，为了避免数据丢失，会开辟一块内存用于存放重写期间产生的写入操作，等到重写完毕后会将这块内存中的操作再追加到aof文件中。

**为什么要重写**

redis中的数据其实有限的，很多数据可能会自动过期，可能会被用户删除，可能会被redis用缓存清除的算法清理掉。redis中的数据会不断淘汰掉旧的，就一部分常用的数据会被自动保留在redis内存中，所以可能很多之前的已经被清理掉的数据， 随着写操作的不断增加, 对应的写日志还停留在AOF中，AOF日志文件就一个，AOF文件会越来越大。

**AOF的rewrite实现：**

rewrite操作对于老日志文件中对于Key的多次操作，**只保留最终的值的那次操作记录到日志文件中**，从而缩小日志文件的大小。
考虑这样一个情况， 如果服务器对键 list 执行了以下四条命令：

RPUSH list 1 2 3 4      // [1, 2, 3, 4]
RPOP list               // [1, 2, 3]
LPOP list               // [2, 3]
LPUSH list 1            // [1, 2, 3]

那么当前列表键 list 在数据库中的值就为 [1, 2, 3] 。

如果我们要保存这个列表的当前状态， 并且尽量减少所使用的命令数， 那么最简单的方式不是去 AOF 文件上分析前面执行的四条命令， 而是直接读取 list 键在数据库的当前值， 然后用一条 RPUSH 1 2 3 命令来代替前面的四条命令。

**AOF的重写rewrite流程**

AOF的重写rewrite流程如下：即是 BGREWRITEAOF 命令的工作原理

**（1）触发重写**：超过AOF的阈值，redis fork一个子进程，进行rewrite操作。子进程基于当前内存中的数据，构建日志，开始往一个新的临时AOF文件中写入日志，：temp-rewriteaof-pid.aof，pid为子进程pid。
**（2）开启 AOF 重写缓冲区**：同时开启 AOF 重写缓冲区，保存这段时间内新增的写指令。
**（3）主进程继续写旧文件**：之前的 AOF 操作保持，继续正常工：redis主进程，接收到client新的写操作之后，写入AOF 重写缓冲区，同时新的命令日志也继续写入旧的AOF文件appendonly.aof。
**（4）AOF重写缓冲区的指令追加新文件**:  重写子进程写入temp-rewriteaof-pid.aof文件结束，redis主进程将将 AOF重写缓冲区的指令追加至新AOF文件 temp-rewriteaof-pid.aof末尾。
**（5）文件替换**：最后用temp-rewriteaof-pid.aof替换旧AOF文件appendonly.aof。

![img](https://img-blog.csdnimg.cn/20190610104317197.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ndWlzdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)

> 在一般情况下在整个 AOF 后台重写过程中， 只有最后的 **AOF重写缓冲区的指令追加新文件** **和改名替换**操作会造成主进程阻塞， 在其他时候， AOF 后台重写都不会对主进程造成阻塞， 这将 AOF 重写对性能造成的影响降到了最低。



## 九、事务

一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。

事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。

Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。



## 十、事件

Redis 服务器是一个事件驱动程序。



### 文件事件

服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。

Redis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。

![](https://i.loli.net/2021/04/10/MV1dn3hO48HNJlf.png)



### 时间事件

服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。

时间事件又分为：

- 定时事件：是让一段程序在指定的时间之内执行一次；
- 周期性事件：是让一段程序每隔指定时间就执行一次。

Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。



### 事件的调度与执行

服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。

从事件处理的角度来看，服务器运行流程如下：

![](https://i.loli.net/2021/04/10/tXoSkHijZMUKIRl.png)



## 十一、复制

通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。

一个从服务器只能有一个主服务器，并且不支持主主复制。



## 十一、复制

通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。

一个从服务器只能有一个主服务器，并且不支持主主复制。

### 连接过程

1. 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；
2. 从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；
3. 主服务器每执行一次写命令，就向从服务器发送相同的写命令。



### 主从链

随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。（**类似于树**）



## 十二、Sentinel

Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。

#### **哨兵模式的作用**

- 通过发送命令，让 Redis 服务器返回监控其运行状态，包括主服务器和从服务器；
- 当哨兵监测到 master 宕机，会自动将 slave 切换成 master ，然后通过**发布订阅模式**通知其他的从服务器，修改配置文件，让它们切换主机；

然而一个哨兵进程对Redis服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。

![多哨兵](https://segmentfault.com/img/remote/1460000022808582)

#### **故障切换的过程**

假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为**主观下线**。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为**客观下线**。这样对于客户端而言，一切都是透明的。

#### 哨兵模式的工作方式：

- 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的 Master 主服务器，Slave 从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。
- 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）
- 如果一个 Master 主服务器被标记为主观下线（SDOWN），则正在监视这个 Master 主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认 Master 主服务器的确进入了主观下线状态
- 当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认 Master 主服务器进入了主观下线状态（SDOWN）， 则 Master 主服务器会被标记为客观下线（ODOWN）
- 在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有 Master 主服务器、Slave 从服务器发送 INFO 命令。
- 当 Master 主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master 主服务器的所有 Slave 从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
- 若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master 主服务器的客观下线状态就会被移除。若 Master 主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。

#### 哨兵模式的优缺点

**优点：**

- 哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。
- 主从可以自动切换，系统更健壮，可用性更高(**可以看作自动版的主从复制**)。

**缺点：**

- Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。



## 十三、分片

分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。

假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，... ，有不同的方式来选择一个指定的键存储在哪个实例中。

- 最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。
- 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。

根据执行分片的位置，可以分为三种分片方式：

- 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。
- 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。
- 服务器分片：Redis Cluster。



## 十四、Redis Cluster

Redis Cluster是一种服务器Sharding技术(分片和路由都是在服务端实现)，**采用多主多从，每一个分区都是由一个Redis主机和多个从机组成，片区和片区之间是相互平行的**。Redis Cluster集群采用了P2P的模式，完全去中心化。

![Redis Cluster数据分片实现原理、及请求路由实现1](https://res-static.hc-cdn.cn/fms/img/6d0f4d1d05093c58e5ed2c358200af1c1603780088378.png)

如上图，官方推荐，集群部署至少要 3 台以上的master节点，最好使用 3 主 3 从六个节点的模式。Redis Cluster集群具有如下几个特点：

- 集群完全去中心化，采用多主多从；所有的redis节点彼此互联(PING-PONG机制)，内部使用二进制协议优化传输速度和带宽。
- 客户端与 Redis 节点直连，不需要中间代理层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。
- 每一个分区都是由一个Redis主机和多个从机组成，片区和片区之间是相互平行的。
- 每一个master节点负责维护一部分槽，以及槽所映射的键值数据。

redis cluster主要是针对海量数据+高并发+高可用的场景，海量数据，如果你的数据量很大，那么建议就用redis cluster，数据量不是很大时，使用sentinel就够了。redis cluster的性能和高可用性均优于哨兵模式。

### 1.分片机制-虚拟槽

Redis Cluster采用虚拟哈希槽分区而非一致性hash算法，预先分配16384(2^14)个卡槽，所有的键根据哈希函数映射到 0 ~ 16383整数槽内，每一个分区内的master节点负责维护一部分槽以及槽所映射的键值数据。

```javascript
#key到hash槽映射算法：对每个key计算CRC16值，然后对16384取模
计算公式：slot = CRC16(key) & 16383
```

![Redis Cluster数据分片实现原理、及请求路由实现2](https://res-static.hc-cdn.cn/fms/img/bdd9242ede86dd18610e4daafa0f5a9e1603780088379.png)

**这种结构很容易添加或者删除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。**使用哈希槽的好处就在于可以方便的添加 或 移除节点，当添加或移除节点时，只需要移动对应槽和数据移动到对应节点就行。

**需要注意的是：**

- (1) hash卡槽只会分配给每个片区的主节点上，从节点不会分配卡槽，从节点会同步master上的hash槽。

- (2)每个hash卡槽可以存放多个Key，每一个数据key对应一个hash槽。

- (3)hash卡槽的目的是确认数据存放到哪个片区的Redis主节点上，实现Redis集群分摊Key。

- (4) 每个片区的Redis主节点卡槽数都对应一个范围，多个片区之间卡槽数范围是等比分配的。比如：存在3个片区对应3个Redis主机，那么3个Redis主机的卡槽总数分别是：16384/3。3个Redis主机的卡槽范围分别是：

  第一台Redis主机：0~5461

  第二台Redis主机：5462 ~ 10922

  第三台Redis主机：10923~16383

- (5)写操作时，会根据Key值计算出对应的卡槽所在的位置，再将数据存入卡槽区对应的master中；读数据也是一样，通过key得到slot，再通过slot找到node获取数据（客户端读请求是打到任意节点上的，当请求的数据没有在接受请求的node上时，会出现重定向，后面有详细讲解）。

- **(6)Redis Cluster的节点之间会共享消息，每个节点都会知道是哪个节点负责哪个范围内的数据槽。**所以客服端请求任意一个节点，都能获取到slot对应的node信息。

**Redis 虚拟槽分区的特点：**

- 解耦数据和节点之间的关系，简化了节点扩容和收缩难度。
- 节点自身维护槽的映射关系，不需要客户端 或 代理服务维护数据分片关系。
- Redis Cluster的节点之间会共享消息，每个节点都知道另外节点负责管理的槽范围。每个节点只能对自己负责的槽进行维护 和 读写操作。

```javascript
1.redis cluster为什么没有使用一致性hash算法，而是使用了哈希槽预分片？ 
缓存热点问题：一致性哈希算法在节点太少时，容易因为数据分布不均匀而造成缓存热点的问题。一致性哈希算法可能集中在某个hash区间内的值特别多，会导致大量的数据涌入同一个节点，造成master的热点问题(如同一时间20W的请求都在某个hash区间内)。

2.redis的hash槽为什么是16384(2^14)个卡槽，而不是65536(2^16)个？
（1）如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。
（2）redis的集群主节点数量基本不可能超过1000个。
	集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。
（3）槽位越小，节点少的情况下，压缩率高。
```

集群配置：

> 1.redis cluster的集群模式可以部分提供服务，当redis.conf的配置cluster-require-full-coverage为no时，表示当一个小主从整体挂掉的时候集群也可以用，也是说0-16383个槽位中，落在该主从对应的slots上面的key是用不了的，但key落在其他的范围是仍然可用的。
>
> 2.在cluster架构下，默认的，一般redis-master用于**接收读写**，而redis-slave则用于备份，当有请求是在向slave发起时，会直接重定向到对应key所在的master来处理。但如果不介意读取的是redis-cluster中有可能过期的数据并且对写请求不感兴趣时，则亦可通过readonly命令，将slave设置成可读，然后通过slave获取相关的key，达到读写分离。
>
> 3.redis-cluster 不可用的情况
> （1）集群**主库半数宕机**（无论是否从库存活）。
> （2）集群某一节点的主从全数宕机。

### 2.Redis cluster伸缩的原理

redis cluster提供了灵活的节点扩容和收缩方案。在不影响集群对外服务的情况下，可以为集群添加节点进行扩容，也可以下线部分节点进行缩容。可以说，槽是 Redis 集群管理数据的基本单位，集群伸缩就是槽和数据在节点之间的移动。

#### **(1)集群扩容**

当一个 Redis 新节点运行并加入现有集群后，我们需要为其迁移槽和槽对应的数据。首先要为新节点指定槽的迁移计划，确保迁移后每个节点负责相似数量的槽，从而保证这些节点的数据均匀。如下图：向有三个master集群中加入M4(即node-4)，集群中槽和数据的迁移。

![Redis Cluster数据分片实现原理、及请求路由实现3](https://res-static.hc-cdn.cn/fms/img/718aab747ec1117f3968ee113d8b3b711603780088379.png)

> 集群扩容过程：
>
> 1.首先启动一个 Redis 节点，记为 M4。
>
> 2.使用 cluster meet 命令，让新 Redis 节点加入到集群中。新节点刚开始都是主节点状态，由于没有负责的槽，所以不能接受任何读写操作，后续我们就给他迁移槽和填充数据。
>
> 3.对M4节点发送 cluster setslot { slot } importing { sourceNodeId } 命令，让目标节点准备导入槽的数据。 对源节点，也就是 M1，M2，M3 节点发送 cluster setslot { slot } migrating { targetNodeId } 命令，让源节点准备迁出槽的数据。
>
> 4.源节点执行 cluster getkeysinslot { slot } { count } 命令，获取 count 个属于槽 { slot } 的键，然后执行步骤五的操作进行迁移键值数据。
>
> 5.在源节点上执行 migrate { targetNodeIp} " " 0 { timeout } keys { key... } 命令，把获取的键通过 pipeline 机制批量迁移到目标节点，批量迁移版本的 migrate 命令在 Redis 3.0.6 以上版本提供。
>
> 6.重复执行步骤 5 和步骤 6 直到槽下所有的键值数据迁移到目标节点。
>
> 7.向集群内所有主节点发送 cluster setslot { slot } node { targetNodeId } 命令，通知槽分配给目标节点。为了保证槽节点映射变更及时传播，需要遍历发送给所有主节点更新被迁移的槽执行新节点

#### (2)集群收缩

收缩节点就是将 Redis 节点下线，整个流程需要如下操作流程：

- 首先需要确认下线节点是否有负责的槽，如果有，需要把槽和对应的数据迁移到其它节点，保证节点下线后整个集群槽节点映射的完整性。
- 当下线节点不再负责槽或者本身是从节点时，就可以通知集群内其他节点忘记下线节点，当所有的节点忘记改节点后可以正常关闭。

下线节点需要将节点自己负责的槽迁移到其他节点，原理与之前节点扩容的迁移槽过程一致。迁移完槽后，还需要通知集群内所有节点忘记下线的节点，也就是说让其它节点不再与要下线的节点进行 Gossip 消息交换。

### 3.客户端请求路由

#### **(1)moved重定向**

![Redis Cluster数据分片实现原理、及请求路由实现4](https://res-static.hc-cdn.cn/fms/img/7e5d992af7995d9d3159016807c8c3eb1603780088381.png)

客服端请求产生moved重定向的执行过程：

- 1.每个节点通过通信都会共享Redis Cluster中槽和集群中对应节点的关系。
- 2.客户端向Redis Cluster的任意节点发送命令，接收命令的节点会根据CRC16规则进行hash运算与16383取余，计算自己的槽和对应节点 。
- 3.如果保存数据的槽被分配给当前节点，则去槽中执行命令，并把命令执行结果返回给客户端。
- 4.如果保存数据的槽不在当前节点的管理范围内，则向客户端返回moved重定向异常 。
- 5.客户端接收到节点返回的结果，如果是moved异常，则从moved异常中获取目标节点的信息。
- 6.客户端向目标节点发送命令，获取命令执行结果。

#### **(2)ask重定向**

在对集群进行扩容和缩容时，需要对槽及槽中数据进行迁移。当槽及槽中数据正在迁移时，客服端请求目标节点时，目标节点中的槽已经迁移支别的节点上了，此时目标节点会返回ask转向给客户端。

![Redis Cluster数据分片实现原理、及请求路由实现5](https://res-static.hc-cdn.cn/fms/img/1506af7ad12b2907e151a42d25bf00671603780088382.png)

当客户端向某个节点发送命令，节点向客户端返回moved异常，告诉客户端数据对应的槽的节点信息；客户端再向正确的节点发送命令时，如果此时正在进行集群扩展或者缩空操作，槽及槽中数据已经被迁移到别的节点了，就会返回ask，这就是ask重定向机制。如下图：

![Redis Cluster数据分片实现原理、及请求路由实现6](https://res-static.hc-cdn.cn/fms/img/43aa78e8efd1fd736fcca2774b2bcb2c1603780088382.png)

**请求执行步骤：**

- 1.当客户端向集群中某个节点发送命令，节点向客户端返回moved异常，告诉客户端数据对应目标槽的节点信息。
- 2.客户端再向目标节点发送命令，目标节点中的槽已经迁移出别的节点上了，此时目标节点会返回ask重定向给客户端。
- 2.客户端向新的target节点发送Asking命令，然后再次向新节点发送请求请求命令。
- 3.新节点target执行命令，把命令执行结果返回给客户端。

> moved和ask重定向的区别：
> 两者都是客户端重定向
> moved异常：槽已经确定迁移，即槽已经**不在**当前节点
> ask异常：槽还在**迁移中**

#### **(3)smart智能客户端**

当数据过多，集群节点较多时，客服端大多数请求都会发生重定向，每次重定向都会产生一次无用的请求，严重影响了redis的性能。如果客户端在请求时就知道由哪个节点负责管理哪个槽，再将请求打到对应的节点上，那就有效的解决了这个问题。

提高redis的性能，避免大部分请求发生重定向，可以使用**智能客户端**。智能客户端知道由哪个节点负责管理哪个槽，而且某个当节点与槽的映射关系发生改变时，客户端也会进行响应的更新，这是一种非常高效的请求方式。

Jedis为Redis Cluster提供了Smart客户端，也就是JedisCluster类。JedisCluster会从集群中选一个可运行的节点，使用 cluster slots 初始化槽和节点映射，将映射关系保存到本地，为每个节点创建JedisPool，相当于为每个redis节点都设置一个JedisPool，然后就可以进行数据读写操作。

![Redis Cluster数据分片实现原理、及请求路由实现7](https://res-static.hc-cdn.cn/fms/img/40e58342a462a422954cdd2023f878851603780088382.png)

**smart智能客户端读写数据命令执行过程如下：**

- 1.JedisCluster启动时，会从集群中选一个可运行的节点，使用 cluster slots 初始化槽和节点映射，将映射关系保存到本地。
- 2.smart 客户端将请求要操作的 key 发送到目标节点，如果请求成功，就得到响应，并返回结果。
- 3.如果目标节点出现连接出错(说明节点的slot->node的映射有更新)，客户端将随机找个活跃节点，向其发送命令，大概率会得到 moved异常，然后根据moved响应更新 slot 和 node 的映射关系，再向新的目标节点发送命令。
- 如果这样的情况连续出现 5 次未找到目标节点，则抛出异常：Too many cluster redirection！。

**总结：**mart智能客户的目标：追求性能。避免了大量请求的moved重定向操作，在数据量和请求量大的环境下，极高的提升了redis性能。

### 4.Redis Cluster主从选举

**当某个master挂掉后，在cluster集群仍然可用的前提下，由于某个master可能有多个slave，某个salve将提升为master节点，那么就会存在竞争，那么此时它们的选举机制是怎样的呢？**

**master节点选举过程：**

- 1.slave发现自己的master变为FAIL。
- 2.发起选举前，slave先给自己的epoch（即currentEpoch）加一，然后请求集群中其它master给自己投票，并广播信息给集群中其他节点。
- 3.slave发起投票后，会等待至少两倍NODE_TIMEOUT时长接收投票结果，不管NODE_TIMEOUT何值，也至少会等待2秒。
- 4.其他节点收到该信息，只有master响应，判断请求者的合法性，并发送结果。
- 5.尝试选举的slave收集master返回的结果，收到超过半投票数master的统一后变成新Master，如果失败会发起第二次选举，选举轮次标记+1继续上面的流程。
- 6.选举成功后，广播Pong消息通知集群其它节点。

> 之所以强制延迟至少0.5秒选举，是为确保master的fail状态在整个集群内传开，否则可能只有小部分master知晓，而master只会给处于fail状态的master的slaves投票。
> 如果一个slave的master状态不是fail，则其它master不会给它投票，Redis通过八卦协议（即Gossip协议，也叫谣言协议）传播fail。
> 而在固定延迟上再加一个随机延迟，是为了避免多个slaves同时发起选举。
>
> #延迟计算公式： DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms
>
> SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举（理论上）。



## 十五、一个简单的论坛系统分析（业务场景）

该论坛系统功能如下：

- 可以发布文章；
- 可以对文章进行点赞；
- 在首页可以按文章的发布时间或者文章的点赞数进行排序显示。



### 文章信息

文章包括标题、作者、赞数等信息，在关系型数据库中很容易构建一张表来存储这些信息，在 Redis 中可以使用 HASH 来存储每种信息以及其对应的值的映射。

Redis 没有关系型数据库中的表这一概念来将同种类型的数据存放在一起，而是使用命名空间的方式来实现这一功能。键名的前面部分存储命名空间，后面部分的内容存储 ID，通常使用 : 来进行分隔。例如下面的 HASH 的键名为 article:92617，其中 article 为命名空间，ID 为 92617。

![](https://i.loli.net/2021/04/10/fQrwEuJFPIxbT1V.png)

### 点赞功能

当有用户为一篇文章点赞时，除了要对该文章的 votes 字段进行加 1 操作，还必须记录该用户已经对该文章进行了点赞，防止用户点赞次数超过 1。可以建立文章的已投票用户集合来进行记录。

为了节约内存，规定一篇文章发布满一周之后，就不能再对它进行投票，而文章的已投票集合也会被删除，可以为文章的已投票集合设置一个一周的过期时间就能实现这个规定。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/485fdf34-ccf8-4185-97c6-17374ee719a0.png)



### 对文章进行排序

为了按发布时间和点赞数进行排序，可以建立一个文章发布时间的有序集合和一个文章点赞数的有序集合。（下图中的 score 就是这里所说的点赞数；下面所示的有序集合分值并不直接是时间和点赞数，而是根据时间和点赞数间接计算出来的）

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f7d170a3-e446-4a64-ac2d-cb95028f81a8.png)