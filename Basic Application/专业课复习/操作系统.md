# 概述

## 基本特征

### 1. 并发

并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。

### 2. 共享

共享是指系统中的资源可以被多个并发进程共同使用。

### 3. 虚拟

虚拟技术把一个物理实体转换为多个逻辑实体。

### 4. 异步

异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。



## 系统调用

如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。

Linux 的系统调用主要有以下这些：

|   Task   | Commands                    |
| :------: | --------------------------- |
| 进程控制 | fork(); exit(); wait();     |
| 进程通信 | pipe(); shmget(); mmap();   |
| 文件操作 | open(); read(); write();    |
| 设备操作 | ioctl(); read(); write();   |
| 信息维护 | getpid(); alarm(); sleep(); |
|   安全   | chmod(); umask(); chown();  |



## 宏内核和微内核

### 1. 宏内核

宏内核是将操作系统功能作为一个紧密结合的整体放到内核。

由于各模块共享信息，因此有很高的性能。

### 2. 微内核

由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。

在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。

因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。



## 中断分类

### 1. 外中断

由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

### 2. 异常

由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

### 3. 陷入

在用户程序中使用系统调用。



# 缓存（Cache）

## **存储器组成**

存储器的三个性能指标——**速度、容量和每位价格**——导致了计算机组成中存储器的多级层次结构，其中主要是缓存和主存、主存和磁盘的结构。

![](https://i.loli.net/2021/04/06/VfreNUCj6Bh8Yxm.png)

如图所示，最上层的是寄存器，最下层的是远程文件系统，从下到上，存储器的速度更快，造价更贵因而容量更小。

 上一层的存储器保存着下一层存储器中部分数据的拷贝，上一层即作为下一层的缓存；

 当需要第k+1层的某个数据时，先在第k层中寻找，若找到，则称为缓存命中，若没找到，则称为缓存不命中；

 当缓存不命中时，需要从第k+1层拷贝需要的数据到第k层，这样就可能会需要替换第k层中已经缓存的某些数据，需要替换时通常会有个替换策略来指导替换哪些数据；



### 寄存器
寄存器是中央处理器（cpu）内的组成部份。寄存器是有限存贮容量的高速存贮部件，它们可用来暂存指令、数据和位址。在中央处理器的控制部件中，包含的寄存器有指令寄存器(IR)和程序计数器(PC)。在中央处理器的算术及逻辑部件中，包含的寄存器有累加器(ACC)。

> 寄存器是CPU内部的元件，寄存器拥有非常高的读写速度，所以在寄存器之间的数据传送非常快。
>

### 高速缓存cache
即高速缓冲存储器，是位于CPU与主内存间的一种容量较小但速度很高的存储器。由于CPU的速度远高于主内存，CPU直接从内存中存取数据要等待一定时间周期，Cache中保存着CPU刚用过或循环使用的一部分数据，当CPU再次使用该部分数据时可从Cache中直接调用,这样就减少了CPU的等待时间,提高了系统的效率。



## **cache意义**

因为CPU的频率太快了，快到主存跟不上，这样在处理器时钟周期内，CPU常常需要等待主存，浪费资源。所以cache的出现，是为了缓解CPU和内存之间速度的不匹配问题。

ache的容量远远小于主存，既然cache不能包含CPU所需要的所有数据，那么cache的存在真的有意义吗？当然是有意义的——局部性原理

> A. 时间局部性：如果某个数据被访问，那么在不久的将来它很可能被再次访问；
> B.空间局部性：如果某个数据被访问，那么与它相邻的数据很快也可能被访问；



## **缓存一致性**

缓存一致性：用于保证多个CPU cache之间缓存共享数据的一致。

多核处理器每个核会有私有cache，也就是内存里的一份数据在多个核上可能有了副本，这多个副本，每个核都可能会对一个内存地址有读写操作，每个核是直接读写自己私有的副本，这就要求各个副本上的读写操作顺序要一致，这和分布式环境下的数据一致性很接近。



## 程序访问的局部性原理

程序访问的局部性原理包括时间局部性和空间局部性。

- 空间局部性：在最近的未来要用到的信息（指令和数据），很可能与现在正在使用的信息在存储空间上是邻近的。例如：遍历二维数组时按行序访问数据元素具有较好的空间局部性
- 时间局部性：在最近的未来要用到的信息，很可能是现在正在使用的信息。例如：重复的引用一个变量时则表现出较好的时间局部性

高速缓冲技术是利用程序访问的局部性原理，把程序中正在使用的部分存放在一个高速的、容量较小的Cache中，使CPU的访存操作大多数针对Cache进行，从而大大提高程序的执行速度。



## 工作原理

Cache位于存储器层次结构的顶层，通常由SRAM构成。

Cache和主存都被分成若干大小相等的块（Cache块又称为Cache行），每块由若干字节组成，块的长度称为块长（Cache行长）。所以Cache中的块数要远少于主存中的块数，它仅保存主存中最活跃的若干块的副本。

CPU与Cache之间的数据交换以字为单位，而Cache与主存之间的数据交换则以Cahce块为单位。

- 当CPU发出读请求时，若访存地址在Cache中命中，就将此地址转换成Cache地址，直接对Cahce进行读操作，与主存无关；若访存地址在Cache中未命中，则需访问主存，并把此字所在的块一次性地从主存调入Cache，若此时Cache已满，则需根据某种 替换算法，用这个块替换Cache中原来的某块信息。

- 当CPU发出写请求时，若Cache命中，有可能会遇到Cache与主存中的内容不一致的问题，此时需要根据某种 写策略 解决这个问题。



## Cahce的性能指标

与Cahce有关的性能指标主要有：命中率，缺失率和平均访问时间。

### 命中率H

- CPU欲访问的信息已在Cache中的比率

### 缺失率M

- CPU欲访问的信息不在Cache中的比率

M = 1 - H

### 平均访问时间 Ta

设 tc 为命中时的Cache访问时间，tm为未命中时的访问时间，则 Ta = H ∗ tc + （ 1 − H ）* tm





## 计算机操作系统中的buffer与cache有什么区别

### 缓冲区（buffer）

将数据写入到内存中，这个存放数据的内存空间在linux系统中一般被称为缓冲区（buffer），例如：写入到内存缓冲区，即写缓冲。

为了提高写操作性能，数据在写入最终介质或下一层级介质前，会合并放在缓冲区中。这样会增加数据持久写的延时，因为第一次写入缓冲区后，在向下写入数据之前，还要等待后续的写入，以便凑够数据或者定时写入到永久存储介质中。

### 缓存区（cache）

从内存里读取数据，这个存放数据的内存空间在linux系统中一般被称为缓存区（cache），例如：从内存读取，即读缓存。

操作系统用缓存来提高文件系统的读性能和内存分配性能，应用程序使用缓存也是为了提升读的访问效率。将经常访问的操作结果保存在缓存中可备随时使用，从而避免了总是执行读磁盘取数据等的一些操作，从而减轻了磁盘的压力。







# 进程管理

## 进程与线程

### 1. 进程

**进程**是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位。

#### 守护进程

**守护进程**（daemon）是生存期长的一种进程，没有控制终端。它们常常在系统引导装入时启动，仅在系统关闭时才终止。UNIX系统有很多守护进程，守护进程程序的名称通常以字母“d”结尾：例如，[syslogd](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/Syslog) 就是指管理系统日志的守护进程。通过ps进程查看器 `ps -efj` 的输出实例，内核守护进程的名字出现在方括号中，大致输出如下：

```bash
UID         PID   PPID   PGID    SID  C STIME TTY          TIME CMD                                                                                                       
root          2      0      0      0  0 14:53 ?        00:00:00 [kthreadd]                                      
root          4      2      0      0  0 14:53 ?        00:00:00 [kworker/0:0H]                                                                        
root          6      2      0      0  0 14:53 ?        00:00:00 [mm_percpu_wq]      
root          7      2      0      0  0 14:53 ?        00:00:02 [ksoftirqd/0]  
root          8      2      0      0  0 14:53 ?        00:00:02 [rcu_sched]                       
root          9      2      0      0  0 14:53 ?        00:00:00 [rcu_bh]                                     
root         10      2      0      0  0 14:53 ?        00:00:00 [migration/0]
root         11      2      0      0  0 14:53 ?        00:00:00 [watchdog/0] 
root         12      2      0      0  0 14:53 ?        00:00:00 [cpuhp/0]    
root         13      2      0      0  0 14:53 ?        00:00:00 [cpuhp/1]
......省略部分输出
```

#### 僵尸进程

有时候有些程序即使执行完了也依然留在进程表中。

那么，这些完成了生命周期但却依然留在进程表中的进程，我们称之为 “僵尸进程”。

##### 它们是如何产生的？

当你运行一个程序时，它会产生一个父进程以及很多子进程。 所有这些子进程都会消耗内核分配给它们的内存和 CPU 资源。

这些子进程完成执行后会发送一个 Exit 信号然后死掉。这个 Exit 信号需要被父进程所读取。父进程需要随后调用 `wait` [命令](https://www.linuxcool.com/)来读取子进程的退出状态，并将子进程从进程表中移除。

若父进程正确第读取了子进程的 Exit 信号，则子进程会从进程表中删掉。

但若父进程未能读取到子进程的 Exit 信号，则这个子进程虽然完成执行处于死亡的状态，但也不会从进程表中删掉。

##### **如何找出僵尸进程**

打开终端并输入下面[命令](https://www.linuxcool.com/):
`ps aux | grep Z`

会列出进程表中所有僵尸进程的详细内容。

##### **如何杀掉僵尸进程**

正常情况下我们可以用 `SIGKILL`信号来杀死进程，但是僵尸进程已经死了， 你不能杀死已经死掉的东西。 因此你需要输入的命令应该是

**`kill -s SIGCHLD pid`**

将这里的 pid 替换成父进程的进程 id，这样父进程就会删除所有以及完成并死掉的子进程了。



### 2. 线程

**线程**是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。

### 3. 区别

Ⅰ 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

Ⅱ 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

## 进程状态的切换

![](https://i.loli.net/2021/03/30/kdjY48y29Zu7KUp.png)

- 就绪状态（ready）：等待被调度
- 运行状态（running）
- 阻塞状态（waiting）：等待资源



## 进程调度算法

### 1. 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

**1.2 短作业优先 shortest job first（SJF）**

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。



### 2. 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**2.1 时间片轮转**

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

**2.2 优先级调度**

**2.3 多级反馈队列**

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。



## 进程同步

### 1. 临界区

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```html
// entry section
// critical section;
// exit section
```

### 2. 同步与互斥

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。

### 3.信号量

信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
- **up** ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

### 4. 管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。





## 进程通信

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

### 1. 管道

linux中：cat a.txt | grep 'hello' |wc -l

管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

它具有以下限制：

- 只支持半双工通信（单向交替传输）；
- 只能在父子进程或者兄弟进程中使用。
- linux中管道为一个4KB大小的缓冲区，read空管道和write满管道会阻塞
- 从管道中读数据时一次性操作，数据一旦被读取，就被从管道中抛弃

### 2. FIFO

也称为命名管道，去除了管道只能在父子进程中使用的限制。

### 3. 消息队列

相比于 FIFO，消息队列具有以下优点：

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

### 4. 信号量

它是一个计数器，用于为多个进程提供对共享数据对象的访问。

### 5. 共享存储

允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用**信号量（p,v操作）**用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

### 6. 套接字

与其它通信机制不同的是，它可用于不同机器间的进程通信。





# 死锁

## 必要条件

- 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
- 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
- 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

## 处理方法

主要有以下四种方法：

- 鸵鸟策略
- 死锁检测与死锁恢复
- 死锁预防
- 死锁避免



# 内存管理

## 虚拟内存

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。

虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。



## 固定分区

将内存分为几个固定的区域，每个区域的大小固定（通常不同），需要加载程序是选择一个闲置且容量足够大的分区进行加载。可能造成一个小程序占用一个大分区的情况，从而造成内存里虽然有小分区闲置但无法加载大程序的情况。



## 非固定分区

非固定分区的思想在于除了划分给OS的空间之外，其余的内存空间是作为一个整体存在的。当一个程序需要占用内存空间时，就在该片空间里面分出一个大小刚刚满足程序所需的空间。再来一个程序时，则在剩下的空间里再这样分出一块来。在这种模式下，一个程序可以加载到任何地方，也可以和物理内存一样大。

- 程序运行时的内存空间会增长，需要预留出增长空间
- 预留太多会造成浪费，太小可能造成程序无法运行或者发生分区交换



## 分页系统地址映射

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

![](https://i.loli.net/2021/03/30/ydoIP2ifQMXhrxw.png)

## 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

### 1. 最佳（OPT）

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。



### 2. 最近最久未使用（LRU, Least Recently Used）

LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

### 3.最近未使用（NRU, Not Recently Used）

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

### 4. 先进先出（FIFO, First In First Out）

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面换出，导致缺页率升高

### 5. 第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

### 6. 时钟（Clock）

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。





## 分段

虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。

下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。

![](https://i.loli.net/2021/03/30/2t6dpuJyse7TWHq.png)

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。



## 段页式

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。



## 分页与分段的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。



# 操作系统中的堆和栈

**栈**（操作系统）：由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈，栈使用的是一级缓存， 他们通常都是被调用时处于存储空间中，调用完毕立即释放

**堆**（操作系统）： 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收，分配方式倒是类似于链表。堆则是存放在二级缓存中，生命周期由虚拟机的垃圾回收算法来决定（并不是一旦成为孤儿对象就能被回收）。所以调用这些对象的速度要相对来得低一些

